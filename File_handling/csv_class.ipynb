{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Practical Course on Handling CSV and JSONL Files in Python\n",
    "\n",
    "Welcome! In the world of data, two of the most common file formats you'll encounter are CSV (Comma-Separated Values) and JSONL (JSON Lines). This notebook will guide you from the basics to advanced techniques for reading and writing these files using Python's powerful standard library.\n",
    "\n",
    "We'll cover:\n",
    "*   What CSV and JSONL files are and when to use them.\n",
    "*   Reading and writing these files using the `csv` and `json` modules.\n",
    "*   Best practices, such as handling headers and ensuring data integrity.\n",
    "*   Advanced topics like CSV dialects and memory-efficient streaming for large files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "**Part 1: Handling CSV Files**\n",
    "1. [Setup: Creating Our Sample CSV File](#setup-csv)\n",
    "2. [The Basics: Reading a CSV with `csv.reader`](#read-csv-basic)\n",
    "3. [A Better Way: Reading a CSV into Dictionaries with `csv.DictReader`](#read-csv-dict)\n",
    "4. [The Basics: Writing Data to a CSV with `csv.writer`](#write-csv-basic)\n",
    "5. [A Better Way: Writing Dictionaries to a CSV with `csv.DictWriter`](#write-csv-dict)\n",
    "6. [Advanced CSV: Handling Different Dialects (e.g., TSV)](#advanced-csv)\n",
    "\n",
    "**Part 2: Handling JSONL Files**\n",
    "7. [Setup: Creating Our Sample JSONL File](#setup-jsonl)\n",
    "8. [Reading a JSONL File](#read-jsonl)\n",
    "9. [Writing to a JSONL File](#write-jsonl)\n",
    "10. [Advanced JSONL: Memory-Efficient Streaming](#advanced-jsonl)\n",
    "\n",
    "**Part 3: Conclusion & Comparison**\n",
    "11. [Summary: CSV vs. JSONL](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Handling CSV Files\n",
    "\n",
    "A CSV file is a simple text file where values are separated by a delimiter, usually a comma. It's great for tabular data, like spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup-csv'></a>\n",
    "### 1. Setup: Creating Our Sample CSV File\n",
    "\n",
    "Let's start by creating a sample CSV file to work with. This cell writes a file named `users.csv` in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users.csv created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Data we want to write\n",
    "csv_data = [\n",
    "    ['ID', 'Name', 'Age', 'City'],\n",
    "    ['101', 'Alice', '30', 'New York'],\n",
    "    ['102', 'Bob', '25', 'Los Angeles'],\n",
    "    ['103', 'Charlie', '35', 'Chicago']\n",
    "]\n",
    "\n",
    "# Writing to users.csv\n",
    "with open('users.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data)\n",
    "\n",
    "print(\"users.csv created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read-csv-basic'></a>\n",
    "### 2. The Basics: Reading a CSV with `csv.reader`\n",
    "\n",
    "The `csv.reader` object is the simplest way to read a CSV. It treats each row as a **list of strings**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x7f078ebb9d90>\n",
      "Header: ['ID', 'Name', 'Age', 'City']\n",
      "--- User Data ---\n",
      "['101', 'Alice', '30', 'New York']\n",
      "The datatype of row is: <class 'list'>\n",
      "ID: 101, Name: Alice, Age: 30 (a <class 'str'>), City: New York\n",
      "['102', 'Bob', '25', 'Los Angeles']\n",
      "The datatype of row is: <class 'list'>\n",
      "ID: 102, Name: Bob, Age: 25 (a <class 'str'>), City: Los Angeles\n",
      "['103', 'Charlie', '35', 'Chicago']\n",
      "The datatype of row is: <class 'list'>\n",
      "ID: 103, Name: Charlie, Age: 35 (a <class 'str'>), City: Chicago\n"
     ]
    }
   ],
   "source": [
    "with open('users.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    print(reader)\n",
    "    # The reader is an iterator. We can skip the header row with next().\n",
    "    header = next(reader)\n",
    "    print(f\"Header: {header}\")\n",
    "    \n",
    "    print(\"--- User Data ---\")\n",
    "    for row in reader:\n",
    "        # Note: All values are read as strings!\n",
    "        print(row)\n",
    "        print(f\"The datatype of row is: {type(row)}\")\n",
    "        user_id, name, age, city = row\n",
    "        print(f\"ID: {user_id}, Name: {name}, Age: {age} (a {type(age)}), City: {city}\")\n",
    "        # You would need to manually convert types, e.g., int(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read-csv-dict'></a>\n",
    "### 3. A Better Way: Reading into Dictionaries with `csv.DictReader`\n",
    "\n",
    "`csv.DictReader` is more convenient. It reads each row into a **dictionary**, using the header row for keys. This makes your code much more readable and less prone to errors if the column order changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- User Data as Dictionaries ---\n",
      "{'ID': '101', 'Name': 'Alice', 'Age': '30', 'City': 'New York'}\n",
      "ID: 101, Name: Alice, City: New York\n",
      "{'ID': '102', 'Name': 'Bob', 'Age': '25', 'City': 'Los Angeles'}\n",
      "ID: 102, Name: Bob, City: Los Angeles\n",
      "{'ID': '103', 'Name': 'Charlie', 'Age': '35', 'City': 'Chicago'}\n",
      "ID: 103, Name: Charlie, City: Chicago\n"
     ]
    }
   ],
   "source": [
    "with open('users.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    print(\"--- User Data as Dictionaries ---\")\n",
    "    for row_dict in reader:\n",
    "        print(row_dict)\n",
    "        # Access data by column name - much better!\n",
    "        print(f\"ID: {row_dict['ID']}, Name: {row_dict['Name']}, City: {row_dict['City']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='write-csv-basic'></a>\n",
    "### 4. The Basics: Writing Data to a CSV with `csv.writer`\n",
    "\n",
    "To write data, we use `csv.writer`. The data should be a list of lists.\n",
    "\n",
    "**Crucial Tip:** Always open the file with `newline=''` when writing CSVs to prevent extra blank rows from being added, especially on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products.csv created successfully.\n"
     ]
    }
   ],
   "source": [
    "products_to_write = [\n",
    "    ['SKU', 'ProductName', 'Price'],\n",
    "    ['P-001', 'Laptop', '1200'],\n",
    "    ['P-002', 'Mouse', '25'],\n",
    "    ['P-003', 'Keyboard', '75']\n",
    "]\n",
    "\n",
    "with open('products.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(products_to_write)\n",
    "\n",
    "print(\"products.csv created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='write-csv-dict'></a>\n",
    "### 5. A Better Way: Writing Dictionaries to a CSV with `csv.DictWriter`\n",
    "\n",
    "If your data is a list of dictionaries, `csv.DictWriter` is the perfect tool. You must specify the `fieldnames` (the column headers) when you create the writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inventory.csv created successfully.\n",
      "--- Inventory Records ---\n",
      "ID: A1, Item: Apple, Stock: 500 (a <class 'str'>), Color: Red\n",
      "ID: B2, Item: Banana, Stock: 800 (a <class 'str'>), Color: Yellow\n",
      "ID: C3, Item: Orange, Stock: 650 (a <class 'str'>), Color: Orange\n"
     ]
    }
   ],
   "source": [
    "inventory_records = [\n",
    "    {'ID': 'A1', 'Item': 'Apple', 'Stock': 500, 'Color': 'Red'},\n",
    "    {'ID': 'B2', 'Item': 'Banana', 'Stock': 800, 'Color': 'Yellow'},\n",
    "    {'ID': 'C3', 'Item': 'Orange', 'Stock': 650, 'Color': 'Orange'}\n",
    "]\n",
    "\n",
    "# Define the headers for your CSV file\n",
    "fieldnames = ['ID', 'Item', 'Stock', 'Color']\n",
    "\n",
    "with open('inventory.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()  # Writes the header row\n",
    "    writer.writerows(inventory_records) # Writes all the dictionary rows\n",
    "\n",
    "print(\"inventory.csv created successfully.\")\n",
    "\n",
    "# reading the inventory.csv file\n",
    "with open('inventory.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    print(\"--- Inventory Records ---\")\n",
    "    for row in reader:\n",
    "        print(f\"ID: {row['ID']}, Item: {row['Item']}, Stock: {row['Stock']} (a {type(row['Stock'])}), Color: {row['Color']}\")\n",
    "        # Note: Stock is still a string, you would need to convert it to int if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='advanced-csv'></a>\n",
    "### 6. Advanced CSV: Handling Different Dialects\n",
    "\n",
    "Not all \"comma-separated\" files actually use commas. Some use tabs (TSV), semicolons, or pipes. The `csv` module can handle this easily by specifying a **dialect**, which includes parameters like `delimiter` and `quotechar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores.tsv created successfully.\n",
      "\n",
      "--- Reading the TSV file ---\n",
      "['Name', 'Score']\n",
      "['Alice', '95']\n",
      "['Bob', '88']\n"
     ]
    }
   ],
   "source": [
    "# Let's create a Tab-Separated-Values (TSV) file\n",
    "data = [['Name', 'Score'], ['Alice', '95'], ['Bob', '88']]\n",
    "\n",
    "with open('scores.tsv', 'w', newline='') as file:\n",
    "    # Here we specify the delimiter is a tab character\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"scores.tsv created successfully.\")\n",
    "\n",
    "# Now let's read it back, telling the reader to expect tabs\n",
    "print(\"\\n--- Reading the TSV file ---\")\n",
    "with open('scores.tsv', 'r') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Handling JSON Lines (JSONL) Files\n",
    "\n",
    "A JSONL file (also called newline-delimited JSON) is a text file where each line is a separate, valid JSON object. This format is fantastic for streaming data and logs because you can process the file one line at a time without loading the whole thing into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup-jsonl'></a>\n",
    "### 7. Setup: Creating Our Sample JSONL File\n",
    "\n",
    "Let's create a `logs.jsonl` file. We will use the standard `json` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs.jsonl created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "log_entries = [\n",
    "    {'timestamp': '2023-10-27T10:00:00Z', 'level': 'INFO', 'message': 'User logged in', 'user_id': '101'},\n",
    "    {'timestamp': '2023-10-27T10:01:30Z', 'level': 'WARN', 'message': 'Failed login attempt', 'ip': '192.168.1.100'},\n",
    "    {'timestamp': '2023-10-27T10:02:00Z', 'level': 'INFO', 'message': 'Data exported', 'user_id': '103'}\n",
    "]\n",
    "\n",
    "with open('logs.jsonl', 'w') as file:\n",
    "    for entry in log_entries:\n",
    "        # Convert the dictionary to a JSON string\n",
    "        json_string = json.dumps(entry)\n",
    "        # Write the string to the file, followed by a newline\n",
    "        file.write(json_string + '\\n')\n",
    "\n",
    "print(\"logs.jsonl created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read-jsonl'></a>\n",
    "### 8. Reading a JSONL File\n",
    "\n",
    "Reading a JSONL file is beautifully simple. You read the file line by line, and use `json.loads()` (load **s**tring) to parse each line from a JSON string into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Parsed Log Entries ---\n",
      "Level: INFO, Message: User logged in\n",
      "Level: WARN, Message: Failed login attempt\n",
      "Level: INFO, Message: Data exported\n"
     ]
    }
   ],
   "source": [
    "parsed_logs = []\n",
    "with open('logs.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        # Each line is a JSON string, parse it into a dictionary\n",
    "        log_dict = json.loads(line)\n",
    "        parsed_logs.append(log_dict)\n",
    "\n",
    "print(\"--- Parsed Log Entries ---\")\n",
    "for log in parsed_logs:\n",
    "    print(f\"Level: {log.get('level')}, Message: {log.get('message')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='write-jsonl'></a>\n",
    "### 9. Writing to a JSONL File\n",
    "\n",
    "Writing is the reverse of reading. For each Python dictionary you want to save, you use `json.dumps()` (dump **s**tring) to convert it to a JSON string and then write that string to the file with a newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended new events to logs.jsonl.\n"
     ]
    }
   ],
   "source": [
    "new_events = [\n",
    "    {'event_id': 500, 'type': 'click', 'element': 'button#submit'},\n",
    "    {'event_id': 501, 'type': 'scroll', 'depth': '75%'}\n",
    "]\n",
    "\n",
    "# Let's append these events to our existing logs file\n",
    "with open('logs.jsonl', 'a') as file: # 'a' for append mode\n",
    "    for event in new_events:\n",
    "        file.write(json.dumps(event) + '\\n')\n",
    "\n",
    "print(\"Appended new events to logs.jsonl.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='advanced-jsonl'></a>\n",
    "### 10. Advanced JSONL: Memory-Efficient Streaming\n",
    "\n",
    "The primary advantage of JSONL is its ability to handle datasets that are too large to fit in memory. You can process the file one record at a time without ever loading the whole thing.\n",
    "\n",
    "Here's how you might process a huge log file to count the number of 'WARN' level messages, using a generator to be extra memory-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 'WARN' level logs found: 1\n"
     ]
    }
   ],
   "source": [
    "def read_logs_stream(filepath):\n",
    "    \"\"\"A generator function that yields one log entry at a time.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle corrupted lines gracefully\n",
    "                print(f\"Skipping corrupted line: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "# Imagine logs.jsonl is 100 GB. This code would still run instantly with minimal memory.\n",
    "warn_count = 0\n",
    "log_stream = read_logs_stream('logs.jsonl')\n",
    "\n",
    "for log_entry in log_stream:\n",
    "    if log_entry.get('level') == 'WARN':\n",
    "        warn_count += 1\n",
    "\n",
    "print(f\"\\nTotal 'WARN' level logs found: {warn_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Conclusion & Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### 11. Summary: CSV vs. JSONL\n",
    "\n",
    "| Feature | CSV (Comma-Separated Values) | JSONL (JSON Lines) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Structure** | Simple, flat, tabular. | Each line is a full JSON object. Can be nested and complex. |\n",
    "| **Schema** | Implicit schema (header row). All rows should have the same columns. | Flexible schema. Each line can have different keys. |\n",
    "| **Data Types** | All data is read as **strings**. Requires manual type conversion. | Preserves data types (strings, numbers, booleans, lists, etc.). |\n",
    "| **Readability** | Human-readable in a spreadsheet. | Human-readable as text, very machine-readable. |\n",
    "| **Best For** | Exporting from spreadsheets, relational databases, simple tabular data. | Logs, streaming API responses, complex records, semi-structured data. |\n",
    "| **Library** | `import csv` | `import json` |\n",
    "\n",
    "You are now equipped with the knowledge to handle two of the most important data formats in Python. Practice by finding sample datasets online and trying to read, transform, and write them!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

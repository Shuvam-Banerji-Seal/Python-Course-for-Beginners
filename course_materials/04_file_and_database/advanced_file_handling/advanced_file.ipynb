{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804e97a9",
   "metadata": {},
   "source": [
    "# A Course on Advanced File Handling in Python\n",
    "\n",
    "Welcome! You've learned the basics of `open()`, `read()`, and `write()`. Now it's time to level up. This notebook covers the advanced techniques and best practices that professional developers use to write robust, efficient, and cross-platform compatible code that interacts with the file system.\n",
    "\n",
    "We will move beyond simple text files and explore how to handle paths, encodings, complex objects, and large datasets gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf3fda",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [The `with` Statement: Context Managers Explained](#context-managers)\n",
    "2. [Mastering File Modes: Beyond 'r' and 'w'](#file-modes)\n",
    "3. [`pathlib`: The Modern, Object-Oriented Way to Handle Paths](#pathlib)\n",
    "4. [Character Encodings: Avoiding the Dreaded `UnicodeDecodeError`](#encoding)\n",
    "5. [Efficiently Processing Large Files](#large-files)\n",
    "6. [Object Serialization with `pickle`](#pickle)\n",
    "7. [In-Memory Files: `io.StringIO` and `io.BytesIO`](#in-memory-files)\n",
    "8. [Temporary Files and Directories](#temp-files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de86d0",
   "metadata": {},
   "source": [
    "<a id='context-managers'></a>\n",
    "## 1. The `with` Statement: Context Managers Explained\n",
    "\n",
    "While not strictly \"advanced,\" understanding *why* the `with` statement is the correct way to handle files is crucial. It uses a concept called a **context manager**.\n",
    "\n",
    "**The Problem:** If you manually `open()` a file, you are responsible for `close()`-ing it. If an error occurs between `open()` and `close()`, the `close()` line might never be reached, leaving the file open and potentially leading to resource leaks or data corruption.\n",
    "\n",
    "**The Solution:** The `with` statement guarantees that the file will be closed automatically, even if errors occur inside the block. It's the standard, safest, and most Pythonic way to work with files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The wrong way (manual close)\n",
    "f = open('bad_example.txt', 'w')\n",
    "# If an error happened here, f.close() would never be called!\n",
    "f.write('hello')\n",
    "f.close()\n",
    "\n",
    "# The right way (using a context manager)\n",
    "try:\n",
    "    with open('good_example.txt', 'w') as f:\n",
    "        f.write('hello\\n')\n",
    "        # Let's cause an error on purpose\n",
    "        f.write(123) # This will raise a TypeError\n",
    "except TypeError as e:\n",
    "    print(f\"Caught an error: {e}\")\n",
    "\n",
    "# Even though an error occurred, the file is guaranteed to be closed.\n",
    "print(f\"Is the file closed? {f.closed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612ed4e",
   "metadata": {},
   "source": [
    "<a id='file-modes'></a>\n",
    "## 2. Mastering File Modes: Beyond 'r' and 'w'\n",
    "\n",
    "The `mode` argument in `open()` is more powerful than you might think.\n",
    "\n",
    "| Mode | Description |\n",
    "| :--- | :--- |\n",
    "| `r`  | **Read** (default). Fails if the file doesn't exist. |\n",
    "| `w`  | **Write**. Creates a new file or **truncates (empties)** an existing one. |\n",
    "| `a`  | **Append**. Creates a new file or adds to the end of an existing one. |\n",
    "| `x`  | **Exclusive Creation**. Creates a new file, but fails if it already exists. |\n",
    "| `b`  | **Binary** mode. For non-text files like images or executables. |\n",
    "| `t`  | **Text** mode (default). For text files. |\n",
    "| `+`  | **Update** (Read and Write). Combined with other modes (e.g., `r+`, `w+`, `a+`). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00962ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'r+' mode: Read and Write. Cursor starts at the beginning.\n",
    "# Useful for updating a file in-place.\n",
    "with open('r_plus_example.txt', 'w') as f:\n",
    "    f.write('Hello World!')\n",
    "\n",
    "with open('r_plus_example.txt', 'r+') as f:\n",
    "    content = f.read()\n",
    "    print(f\"Original content: {content}\")\n",
    "    # Move cursor back to the beginning to overwrite\n",
    "    f.seek(0)\n",
    "    f.write('Jello') # Overwrites the first 5 characters\n",
    "\n",
    "with open('r_plus_example.txt', 'r') as f:\n",
    "    print(f\"Updated content:  {f.read()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07920f1b",
   "metadata": {},
   "source": [
    "<a id='pathlib'></a>\n",
    "## 3. `pathlib`: The Modern, Object-Oriented Way to Handle Paths\n",
    "\n",
    "The built-in `pathlib` module (introduced in Python 3.4) is the recommended way to handle file system paths. It provides an object-oriented interface, making path manipulation more intuitive and less error-prone than using string manipulation or the older `os.path` module.\n",
    "\n",
    "**Benefits:**\n",
    "- **Cross-Platform:** Automatically handles differences between Windows (`\\`) and Unix/macOS (`/`).\n",
    "- **Readable:** `path / 'subdir' / 'file.txt'` is cleaner than `os.path.join(path, 'subdir', 'file.txt')`.\n",
    "- **Powerful:** Objects have useful methods and properties built-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create a Path object\n",
    "p = Path('my_data_folder')\n",
    "\n",
    "# Create a directory\n",
    "p.mkdir(exist_ok=True) # exist_ok=True prevents an error if it already exists\n",
    "\n",
    "# Create a path to a file inside the directory using the / operator\n",
    "file_path = p / 'report.txt'\n",
    "print(f\"Path object: {file_path}\")\n",
    "\n",
    "# Write text to the file directly from the Path object\n",
    "file_path.write_text('This is the first line of the report.')\n",
    "\n",
    "# Read text directly\n",
    "content = file_path.read_text()\n",
    "print(f\"File content: {content}\")\n",
    "\n",
    "# Check for existence\n",
    "print(f\"Does the file exist? {file_path.exists()}\")\n",
    "print(f\"Is it a file? {file_path.is_file()}\")\n",
    "print(f\"Is it a directory? {file_path.is_dir()}\")\n",
    "\n",
    "# Get parts of the path\n",
    "print(f\"File name: {file_path.name}\")\n",
    "print(f\"File stem (name without extension): {file_path.stem}\")\n",
    "print(f\"File extension: {file_path.suffix}\")\n",
    "print(f\"Parent directory: {file_path.parent}\")\n",
    "\n",
    "# Clean up\n",
    "file_path.unlink() # Delete the file\n",
    "p.rmdir() # Delete the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86545b8",
   "metadata": {},
   "source": [
    "<a id='encoding'></a>\n",
    "## 4. Character Encodings: Avoiding `UnicodeDecodeError`\n",
    "\n",
    "A computer only understands bytes (numbers). An **encoding** is a rulebook for translating text characters (like 'A', '€', '✓') into bytes.\n",
    "\n",
    "- `ASCII` is a very old, small encoding for English characters.\n",
    "- `UTF-8` is the modern standard. It can represent any character from any language and is backward-compatible with ASCII.\n",
    "\n",
    "A `UnicodeDecodeError` happens when you try to read a file using the wrong encoding \"rulebook.\"\n",
    "\n",
    "**Best Practice:** Always explicitly specify the encoding when working with text files. `encoding='utf-8'` is the safest choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98691aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_special_chars = '¡Hola, mundo! This costs 5€.'\n",
    "\n",
    "# Write the file using UTF-8 (the correct way)\n",
    "with open('encoded_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(text_with_special_chars)\n",
    "\n",
    "# Now, let's try to read it with the wrong encoding (ASCII) to trigger an error\n",
    "try:\n",
    "    with open('encoded_text.txt', 'r', encoding='ascii') as f:\n",
    "        content = f.read()\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "    print(\"This happened because ASCII doesn't know how to decode '¡' or '€'.\")\n",
    "\n",
    "# Now, read it with the correct encoding\n",
    "with open('encoded_text.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    print(f\"\\nSuccessfully read content: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f076aca",
   "metadata": {},
   "source": [
    "<a id='large-files'></a>\n",
    "## 5. Efficiently Processing Large Files\n",
    "\n",
    "Calling `file.read()` on a multi-gigabyte file will load the entire file into RAM and likely crash your program. The correct way to handle large files is to process them in chunks or line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Iterating line by line (best for text files)\n",
    "# This reads only one line into memory at a time.\n",
    "print(\"--- Processing line by line ---\")\n",
    "with open('good_example.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        print(f\"Processing line: {line.strip()}\") # .strip() removes leading/trailing whitespace\n",
    "\n",
    "# Method 2: Reading in fixed-size chunks (best for binary files)\n",
    "# Let's pretend our text file is a large binary file.\n",
    "print(\"\\n--- Processing in chunks of 10 bytes ---\")\n",
    "with open('encoded_text.txt', 'rb') as f: # Open in binary mode 'rb'\n",
    "    chunk = f.read(10) # Read the first 10 bytes\n",
    "    while chunk:\n",
    "        print(f\"Read chunk: {chunk}\")\n",
    "        chunk = f.read(10) # Read the next 10 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17a3b2",
   "metadata": {},
   "source": [
    "<a id='pickle'></a>\n",
    "## 6. Object Serialization with `pickle`\n",
    "\n",
    "**Serialization** is the process of converting a Python object (like a dictionary, list, or custom class instance) into a byte stream that can be saved to a file. **Deserialization** is the reverse process.\n",
    "\n",
    "Python's `pickle` module is the standard way to do this.\n",
    "\n",
    "> **Security Warning:** Never unpickle data from an untrusted or unauthenticated source. A malicious pickle file can execute arbitrary code on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd401232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Let's create a complex object to save\n",
    "data_to_save = {\n",
    "    'name': 'Project Alpha',\n",
    "    'id': 12345,\n",
    "    'members': ['Alice', 'Bob', 'Charlie'],\n",
    "    'is_active': True\n",
    "}\n",
    "\n",
    "# Serialize and save the object to a file\n",
    "# Note: we must use binary write mode 'wb'\n",
    "with open('project_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)\n",
    "\n",
    "print(\"Object saved to project_data.pkl\")\n",
    "\n",
    "# Now, load it back from the file\n",
    "# Note: we must use binary read mode 'rb'\n",
    "with open('project_data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "print(f\"\\nLoaded object type: {type(loaded_data)}\")\n",
    "print(f\"Loaded object content: {loaded_data}\")\n",
    "print(f\"Project members: {loaded_data['members']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd16ad8",
   "metadata": {},
   "source": [
    "<a id='in-memory-files'></a>\n",
    "## 7. In-Memory Files: `io.StringIO` and `io.BytesIO`\n",
    "\n",
    "Sometimes you need to work with an API or library that expects a file object, but the data you have is just a string or bytes in memory. The `io` module lets you create **file-like objects** that behave like real files but operate entirely in RAM.\n",
    "\n",
    "- `io.StringIO`: For text data.\n",
    "- `io.BytesIO`: For binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# Imagine you have CSV data as a string, not a file\n",
    "csv_string = \"col1,col2\\n1,2\\n3,4\"\n",
    "\n",
    "# pd.read_csv can read from a file path OR a file-like object\n",
    "string_file = io.StringIO(csv_string)\n",
    "\n",
    "# Now we can pass this in-memory file to pandas\n",
    "df = pd.read_csv(string_file)\n",
    "\n",
    "print(\"DataFrame created from an in-memory string file:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a366e",
   "metadata": {},
   "source": [
    "<a id='temp-files'></a>\n",
    "## 8. Temporary Files and Directories\n",
    "\n",
    "The `tempfile` module is perfect for when you need a temporary file or directory for intermediate data processing, without polluting your file system. These files are securely created and are automatically deleted when the context manager exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    print(f\"Created temporary directory: {temp_dir}\")\n",
    "    temp_file_path = os.path.join(temp_dir, 'my_temp_file.txt')\n",
    "    \n",
    "    with open(temp_file_path, 'w') as f:\n",
    "        f.write('Temporary data')\n",
    "        \n",
    "    print(f\"File exists inside the 'with' block? {os.path.exists(temp_file_path)}\")\n",
    "\n",
    "print(f\"\\nDirectory exists after the 'with' block? {os.path.exists(temp_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d94e6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've now explored the key techniques for professional-grade file handling in Python. By mastering context managers, `pathlib`, encodings, and efficient processing, you can write code that is safer, more reliable, and more performant.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- **Always use `with`** for automatic resource management.\n",
    "- **Use `pathlib`** for modern, object-oriented path manipulation.\n",
    "- **Always specify `encoding='utf-8'`** for text files.\n",
    "- **Iterate over large files**; don't read them all at once.\n",
    "- **Use `pickle`** to save Python objects, but be wary of its security risks.\n",
    "- **Use `io.StringIO`** to treat strings like files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

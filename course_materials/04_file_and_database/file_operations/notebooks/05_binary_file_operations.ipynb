{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary File Operations: Complete Guide\n",
    "\n",
    "Binary files store data in a format that computers can read directly, without text encoding. This notebook covers all binary file operations including pickle serialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔢 Understanding Binary Files\n",
    "\n",
    "**Binary files** contain data in binary format (0s and 1s) that is not human-readable. Examples include:\n",
    "- Images (PNG, JPEG)\n",
    "- Videos (MP4, AVI)\n",
    "- Executables (.exe, .app)\n",
    "- Pickle files (.pkl)\n",
    "- Database files\n",
    "\n",
    "**Key differences from text files:**\n",
    "- No character encoding/decoding\n",
    "- More compact storage\n",
    "- Faster read/write operations\n",
    "- Platform-independent (when done correctly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 Binary File Modes\n",
    "\n",
    "All binary modes include the 'b' character:\n",
    "\n",
    "| Mode | Description | Creates File? | Truncates? | Position |\n",
    "|------|-------------|---------------|------------|----------|\n",
    "| `rb` | Read binary | No | No | Beginning |\n",
    "| `wb` | Write binary | Yes | Yes | Beginning |\n",
    "| `ab` | Append binary | Yes | No | End |\n",
    "| `rb+` | Read/Write binary | No | No | Beginning |\n",
    "| `wb+` | Write/Read binary | Yes | Yes | Beginning |\n",
    "| `ab+` | Append/Read binary | Yes | No | End |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Basic Binary File Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Binary File Modes Demonstration\n",
      "==================================================\n",
      "📊 Sample data: b'Hello World!'\n",
      "📝 As text: Hello World!\n",
      "\n",
      "--- Mode 'wb' (Write Binary) ---\n",
      "✅ Wrote 12 bytes\n",
      "\n",
      "--- Mode 'rb' (Read Binary) ---\n",
      "📖 Read: b'Hello World!'\n",
      "📝 As text: Hello World!\n",
      "✅ Data matches: True\n",
      "\n",
      "--- Mode 'ab' (Append Binary) ---\n",
      "✅ Appended 9 bytes\n",
      "📖 Combined data: b'Hello World!\\nGoodbye!'\n",
      "📝 As text: Hello World!\n",
      "Goodbye!\n",
      "\n",
      "--- Mode 'rb+' (Read/Write Binary) ---\n",
      "📖 First 5 bytes: b'Hello' (Hello)\n",
      "📍 Current position: 5\n",
      "✅ Overwrote 3 bytes with 'XYZ'\n",
      "📖 Modified data: b'HelloXYZrld!\\nGoodbye!'\n",
      "📝 As text: HelloXYZrld!\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create sample_files directory\n",
    "Path('../sample_files').mkdir(exist_ok=True)\n",
    "\n",
    "def demonstrate_binary_modes():\n",
    "    \"\"\"Demonstrate all binary file modes\"\"\"\n",
    "    print(\"🔢 Binary File Modes Demonstration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Sample binary data\n",
    "    sample_data = bytes([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33])  # \"Hello World!\"\n",
    "    additional_data = bytes([10, 71, 111, 111, 100, 98, 121, 101, 33])  # \"\\nGoodbye!\"\n",
    "    \n",
    "    print(f\"📊 Sample data: {sample_data}\")\n",
    "    print(f\"📝 As text: {sample_data.decode('utf-8')}\")\n",
    "    \n",
    "    # Mode 'wb' - Write Binary\n",
    "    print(\"\\n--- Mode 'wb' (Write Binary) ---\")\n",
    "    with open('../sample_files/binary_demo.bin', 'wb') as f:\n",
    "        bytes_written = f.write(sample_data)\n",
    "        print(f\"✅ Wrote {bytes_written} bytes\")\n",
    "    \n",
    "    # Mode 'rb' - Read Binary\n",
    "    print(\"\\n--- Mode 'rb' (Read Binary) ---\")\n",
    "    with open('../sample_files/binary_demo.bin', 'rb') as f:\n",
    "        read_data = f.read()\n",
    "        print(f\"📖 Read: {read_data}\")\n",
    "        print(f\"📝 As text: {read_data.decode('utf-8')}\")\n",
    "        print(f\"✅ Data matches: {read_data == sample_data}\")\n",
    "    \n",
    "    # Mode 'ab' - Append Binary\n",
    "    print(\"\\n--- Mode 'ab' (Append Binary) ---\")\n",
    "    with open('../sample_files/binary_demo.bin', 'ab') as f:\n",
    "        bytes_written = f.write(additional_data)\n",
    "        print(f\"✅ Appended {bytes_written} bytes\")\n",
    "    \n",
    "    # Read the combined result\n",
    "    with open('../sample_files/binary_demo.bin', 'rb') as f:\n",
    "        combined_data = f.read()\n",
    "        print(f\"📖 Combined data: {combined_data}\")\n",
    "        print(f\"📝 As text: {combined_data.decode('utf-8')}\")\n",
    "    \n",
    "    # Mode 'rb+' - Read/Write Binary\n",
    "    print(\"\\n--- Mode 'rb+' (Read/Write Binary) ---\")\n",
    "    with open('../sample_files/binary_demo.bin', 'rb+') as f:\n",
    "        # Read first 5 bytes\n",
    "        first_part = f.read(5)\n",
    "        print(f\"📖 First 5 bytes: {first_part} ({first_part.decode('utf-8')})\")\n",
    "        \n",
    "        # Get current position\n",
    "        pos = f.tell()\n",
    "        print(f\"📍 Current position: {pos}\")\n",
    "        \n",
    "        # Write at current position (overwrite)\n",
    "        f.write(b'XYZ')\n",
    "        print(\"✅ Overwrote 3 bytes with 'XYZ'\")\n",
    "    \n",
    "    # Read the modified result\n",
    "    with open('../sample_files/binary_demo.bin', 'rb') as f:\n",
    "        modified_data = f.read()\n",
    "        print(f\"📖 Modified data: {modified_data}\")\n",
    "        print(f\"📝 As text: {modified_data.decode('utf-8', errors='replace')}\")\n",
    "\n",
    "demonstrate_binary_modes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🥒 Pickle Module: Serializing Python Objects\n",
    "\n",
    "The `pickle` module allows you to serialize (convert to bytes) and deserialize (convert back) Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🥒 Pickle Module Demonstration\n",
      "========================================\n",
      "📊 Original data type: <class 'dict'>\n",
      "📝 Sample content: Alice Johnson, GPA: 4.2\n",
      "\n",
      "--- Method 1: dump() and load() ---\n",
      "✅ Data serialized with pickle.dump()\n",
      "📏 Pickle file size: 231 bytes\n",
      "✅ Data deserialized with pickle.load()\n",
      "🔍 Data integrity check: True\n",
      "📊 Loaded data type: <class 'dict'>\n",
      "\n",
      "--- Method 2: dumps() and loads() (in-memory) ---\n",
      "✅ Serialized to bytes: 231 bytes\n",
      "📊 First 50 bytes: b'\\x80\\x04\\x95\\xdc\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\x04name\\x94\\x8c\\rAlice Johnson\\x94\\x8c\\x02id\\x94M90\\x8c\\x06gra'\n",
      "✅ Deserialized from bytes\n",
      "🔍 Data integrity check: True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "def demonstrate_pickle_operations():\n",
    "    \"\"\"Comprehensive pickle demonstration\"\"\"\n",
    "    print(\"🥒 Pickle Module Demonstration\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create complex data structures to pickle\n",
    "    student_data = {\n",
    "        'name': 'Alice Johnson',\n",
    "        'id': 12345,\n",
    "        'grades': [85, 92, 78, 96, 88],\n",
    "        'subjects': ['Math', 'Physics', 'Chemistry', 'Biology'],\n",
    "        'metadata': {\n",
    "            'enrollment_date': '2024-01-15',\n",
    "            'active': True,\n",
    "            'gpa': 4.2\n",
    "        },\n",
    "        'test_scores': [(85, 'Math'), (92, 'Physics'), (78, 'Chemistry')]\n",
    "    }\n",
    "    \n",
    "    print(f\"📊 Original data type: {type(student_data)}\")\n",
    "    print(f\"📝 Sample content: {student_data['name']}, GPA: {student_data['metadata']['gpa']}\")\n",
    "    \n",
    "    # Method 1: Using dump() and load()\n",
    "    print(\"\\n--- Method 1: dump() and load() ---\")\n",
    "    \n",
    "    # Serialize (dump) to file\n",
    "    pickle_file = '../sample_files/student_data.pkl'\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(student_data, f)\n",
    "    print(\"✅ Data serialized with pickle.dump()\")\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = os.path.getsize(pickle_file)\n",
    "    print(f\"📏 Pickle file size: {file_size} bytes\")\n",
    "    \n",
    "    # Deserialize (load) from file\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    print(\"✅ Data deserialized with pickle.load()\")\n",
    "    \n",
    "    # Verify data integrity\n",
    "    print(f\"🔍 Data integrity check: {loaded_data == student_data}\")\n",
    "    print(f\"📊 Loaded data type: {type(loaded_data)}\")\n",
    "    \n",
    "    # Method 2: Using dumps() and loads() (in-memory)\n",
    "    print(\"\\n--- Method 2: dumps() and loads() (in-memory) ---\")\n",
    "    \n",
    "    # Serialize to bytes\n",
    "    serialized_bytes = pickle.dumps(student_data)\n",
    "    print(f\"✅ Serialized to bytes: {len(serialized_bytes)} bytes\")\n",
    "    print(f\"📊 First 50 bytes: {serialized_bytes[:50]}\")\n",
    "    \n",
    "    # Deserialize from bytes\n",
    "    deserialized_data = pickle.loads(serialized_bytes)\n",
    "    print(f\"✅ Deserialized from bytes\")\n",
    "    print(f\"🔍 Data integrity check: {deserialized_data == student_data}\")\n",
    "\n",
    "demonstrate_pickle_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Binary File Search Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Binary File Search Operations\n",
      "========================================\n",
      "✅ Saved 5 student records\n",
      "🎯 Found student 102: Bob, Grade: 92\n",
      "🎯 Found student 105: Eve, Grade: 88\n",
      "❌ Student 999 not found\n",
      "\n",
      "🏆 High performers (85-95): 3 students\n",
      "   Alice: 85\n",
      "   Bob: 92\n",
      "   Eve: 88\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_binary_search():\n",
    "    \"\"\"Demonstrate searching in binary files\"\"\"\n",
    "    print(\"🔍 Binary File Search Operations\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create a binary file with multiple records\n",
    "    students = [\n",
    "        {'id': 101, 'name': 'Alice', 'grade': 85},\n",
    "        {'id': 102, 'name': 'Bob', 'grade': 92},\n",
    "        {'id': 103, 'name': 'Charlie', 'grade': 78},\n",
    "        {'id': 104, 'name': 'Diana', 'grade': 96},\n",
    "        {'id': 105, 'name': 'Eve', 'grade': 88}\n",
    "    ]\n",
    "    \n",
    "    # Save all students to binary file\n",
    "    students_file = '../sample_files/students.pkl'\n",
    "    with open(students_file, 'wb') as f:\n",
    "        for student in students:\n",
    "            pickle.dump(student, f)\n",
    "    print(f\"✅ Saved {len(students)} student records\")\n",
    "    \n",
    "    # Search function\n",
    "    def search_student_by_id(filename, target_id):\n",
    "        \"\"\"Search for a student by ID in binary file\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                while True:\n",
    "                    try:\n",
    "                        student = pickle.load(f)\n",
    "                        if student['id'] == target_id:\n",
    "                            return student\n",
    "                    except EOFError:\n",
    "                        break  # End of file reached\n",
    "            return None  # Student not found\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ File not found: {filename}\")\n",
    "            return None\n",
    "    \n",
    "    # Search for specific students\n",
    "    search_ids = [102, 105, 999]  # 999 doesn't exist\n",
    "    \n",
    "    for student_id in search_ids:\n",
    "        result = search_student_by_id(students_file, student_id)\n",
    "        if result:\n",
    "            print(f\"🎯 Found student {student_id}: {result['name']}, Grade: {result['grade']}\")\n",
    "        else:\n",
    "            print(f\"❌ Student {student_id} not found\")\n",
    "    \n",
    "    # Search by grade range\n",
    "    def search_students_by_grade_range(filename, min_grade, max_grade):\n",
    "        \"\"\"Find all students within a grade range\"\"\"\n",
    "        matching_students = []\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                while True:\n",
    "                    try:\n",
    "                        student = pickle.load(f)\n",
    "                        if min_grade <= student['grade'] <= max_grade:\n",
    "                            matching_students.append(student)\n",
    "                    except EOFError:\n",
    "                        break\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ File not found: {filename}\")\n",
    "        \n",
    "        return matching_students\n",
    "    \n",
    "    # Find students with grades between 85 and 95\n",
    "    high_performers = search_students_by_grade_range(students_file, 85, 95)\n",
    "    print(f\"\\n🏆 High performers (85-95): {len(high_performers)} students\")\n",
    "    for student in high_performers:\n",
    "        print(f\"   {student['name']}: {student['grade']}\")\n",
    "\n",
    "demonstrate_binary_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✏️ Binary File Update Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_binary_updates():\n",
    "    \"\"\"Demonstrate updating records in binary files\"\"\"\n",
    "    print(\"✏️ Binary File Update Operations\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create initial data\n",
    "    products = [\n",
    "        {'id': 'P001', 'name': 'Laptop', 'price': 999.99, 'stock': 10},\n",
    "        {'id': 'P002', 'name': 'Mouse', 'price': 29.99, 'stock': 50},\n",
    "        {'id': 'P003', 'name': 'Keyboard', 'price': 79.99, 'stock': 25}\n",
    "    ]\n",
    "    \n",
    "    products_file = '../sample_files/products.pkl'\n",
    "    \n",
    "    # Save initial data\n",
    "    with open(products_file, 'wb') as f:\n",
    "        pickle.dump(products, f)\n",
    "    print(f\"✅ Saved {len(products)} products\")\n",
    "    \n",
    "    # Display current data\n",
    "    def display_products(filename):\n",
    "        \"\"\"Display all products from file\"\"\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            products = pickle.load(f)\n",
    "        \n",
    "        print(\"📦 Current Products:\")\n",
    "        for product in products:\n",
    "            print(f\"   {product['id']}: {product['name']} - ${product['price']:.2f} (Stock: {product['stock']})\")\n",
    "    \n",
    "    display_products(products_file)\n",
    "    \n",
    "    # Update function\n",
    "    def update_product_price(filename, product_id, new_price):\n",
    "        \"\"\"Update the price of a specific product\"\"\"\n",
    "        # Read all data\n",
    "        with open(filename, 'rb') as f:\n",
    "            products = pickle.load(f)\n",
    "        \n",
    "        # Find and update the product\n",
    "        updated = False\n",
    "        for product in products:\n",
    "            if product['id'] == product_id:\n",
    "                old_price = product['price']\n",
    "                product['price'] = new_price\n",
    "                print(f\"✅ Updated {product_id}: ${old_price:.2f} → ${new_price:.2f}\")\n",
    "                updated = True\n",
    "                break\n",
    "        \n",
    "        if not updated:\n",
    "            print(f\"❌ Product {product_id} not found\")\n",
    "            return False\n",
    "        \n",
    "        # Write back all data\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(products, f)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # Update stock function\n",
    "    def update_product_stock(filename, product_id, quantity_change):\n",
    "        \"\"\"Update the stock of a specific product\"\"\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            products = pickle.load(f)\n",
    "        \n",
    "        updated = False\n",
    "        for product in products:\n",
    "            if product['id'] == product_id:\n",
    "                old_stock = product['stock']\n",
    "                product['stock'] += quantity_change\n",
    "                print(f\"✅ Updated {product_id} stock: {old_stock} → {product['stock']} ({quantity_change:+d})\")\n",
    "                updated = True\n",
    "                break\n",
    "        \n",
    "        if not updated:\n",
    "            print(f\"❌ Product {product_id} not found\")\n",
    "            return False\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(products, f)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # Perform updates\n",
    "    print(\"\\n🔄 Performing Updates:\")\n",
    "    update_product_price(products_file, 'P001', 899.99)  # Reduce laptop price\n",
    "    update_product_stock(products_file, 'P002', -5)      # Sell 5 mice\n",
    "    update_product_stock(products_file, 'P003', 10)      # Restock keyboards\n",
    "    \n",
    "    print(\"\\n📦 After Updates:\")\n",
    "    display_products(products_file)\n",
    "    \n",
    "    # Add new product function\n",
    "    def add_product(filename, new_product):\n",
    "        \"\"\"Add a new product to the file\"\"\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            products = pickle.load(f)\n",
    "        \n",
    "        # Check if product ID already exists\n",
    "        for product in products:\n",
    "            if product['id'] == new_product['id']:\n",
    "                print(f\"❌ Product {new_product['id']} already exists\")\n",
    "                return False\n",
    "        \n",
    "        products.append(new_product)\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(products, f)\n",
    "        \n",
    "        print(f\"✅ Added new product: {new_product['id']} - {new_product['name']}\")\n",
    "        return True\n",
    "    \n",
    "    # Add a new product\n",
    "    new_product = {'id': 'P004', 'name': 'Monitor', 'price': 299.99, 'stock': 15}\n",
    "    add_product(products_file, new_product)\n",
    "    \n",
    "    print(\"\\n📦 After Adding New Product:\")\n",
    "    display_products(products_file)\n",
    "\n",
    "demonstrate_binary_updates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Binary File Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "def performance_comparison():\n",
    "    \"\"\"Compare binary vs text file performance\"\"\"\n",
    "    print(\"📊 Binary vs Text File Performance\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Create test data\n",
    "    test_data = []\n",
    "    for i in range(1000):\n",
    "        test_data.append({\n",
    "            'id': i,\n",
    "            'name': f'User_{i:04d}',\n",
    "            'email': f'user{i}@example.com',\n",
    "            'scores': [i % 100, (i * 2) % 100, (i * 3) % 100],\n",
    "            'active': i % 2 == 0\n",
    "        })\n",
    "    \n",
    "    print(f\"📝 Test data: {len(test_data)} records\")\n",
    "    \n",
    "    # Binary file operations\n",
    "    binary_file = '../sample_files/performance_test.pkl'\n",
    "    \n",
    "    # Write binary\n",
    "    start_time = time.time()\n",
    "    with open(binary_file, 'wb') as f:\n",
    "        pickle.dump(test_data, f)\n",
    "    binary_write_time = time.time() - start_time\n",
    "    \n",
    "    # Read binary\n",
    "    start_time = time.time()\n",
    "    with open(binary_file, 'rb') as f:\n",
    "        binary_loaded = pickle.load(f)\n",
    "    binary_read_time = time.time() - start_time\n",
    "    \n",
    "    # Text file operations (JSON)\n",
    "    json_file = '../sample_files/performance_test.json'\n",
    "    \n",
    "    # Write JSON\n",
    "    start_time = time.time()\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(test_data, f)\n",
    "    json_write_time = time.time() - start_time\n",
    "    \n",
    "    # Read JSON\n",
    "    start_time = time.time()\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        json_loaded = json.load(f)\n",
    "    json_read_time = time.time() - start_time\n",
    "    \n",
    "    # Get file sizes\n",
    "    binary_size = os.path.getsize(binary_file)\n",
    "    json_size = os.path.getsize(json_file)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n⏱️ Performance Results:\")\n",
    "    print(f\"   Binary write: {binary_write_time:.4f}s\")\n",
    "    print(f\"   JSON write:   {json_write_time:.4f}s\")\n",
    "    print(f\"   Binary read:  {binary_read_time:.4f}s\")\n",
    "    print(f\"   JSON read:    {json_read_time:.4f}s\")\n",
    "    \n",
    "    print(f\"\\n💾 File Sizes:\")\n",
    "    print(f\"   Binary file: {binary_size:,} bytes\")\n",
    "    print(f\"   JSON file:   {json_size:,} bytes\")\n",
    "    print(f\"   Size ratio:  {json_size/binary_size:.2f}x (JSON vs Binary)\")\n",
    "    \n",
    "    print(f\"\\n🚀 Speed Comparison:\")\n",
    "    print(f\"   Binary is {json_write_time/binary_write_time:.1f}x faster for writing\")\n",
    "    print(f\"   Binary is {json_read_time/binary_read_time:.1f}x faster for reading\")\n",
    "    \n",
    "    # Verify data integrity\n",
    "    print(f\"\\n🔍 Data Integrity:\")\n",
    "    print(f\"   Binary data matches: {binary_loaded == test_data}\")\n",
    "    print(f\"   JSON data matches:   {json_loaded == test_data}\")\n",
    "    \n",
    "    # Clean up large files\n",
    "    os.remove(binary_file)\n",
    "    os.remove(json_file)\n",
    "    print(f\"\\n🧹 Cleaned up test files\")\n",
    "\n",
    "performance_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔒 Binary File Best Practices and Security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_best_practices():\n",
    "    \"\"\"Show best practices for binary file operations\"\"\"\n",
    "    print(\"🔒 Binary File Best Practices\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # 1. Always use context managers\n",
    "    print(\"\\n1. ✅ Always use context managers (with statement)\")\n",
    "    \n",
    "    # Good practice\n",
    "    data = {'message': 'Hello, World!'}\n",
    "    with open('../sample_files/good_practice.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(\"   ✅ File automatically closed even if error occurs\")\n",
    "    \n",
    "    # 2. Handle exceptions properly\n",
    "    print(\"\\n2. ✅ Handle exceptions properly\")\n",
    "    \n",
    "    def safe_pickle_load(filename):\n",
    "        \"\"\"Safely load pickle file with error handling\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ❌ File not found: {filename}\")\n",
    "            return None\n",
    "        except pickle.UnpicklingError:\n",
    "            print(f\"   ❌ Invalid pickle file: {filename}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Unexpected error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Test with valid file\n",
    "    result = safe_pickle_load('../sample_files/good_practice.pkl')\n",
    "    print(f\"   ✅ Loaded data: {result}\")\n",
    "    \n",
    "    # Test with non-existent file\n",
    "    result = safe_pickle_load('../sample_files/nonexistent.pkl')\n",
    "    \n",
    "    # 3. Validate data after loading\n",
    "    print(\"\\n3. ✅ Validate data after loading\")\n",
    "    \n",
    "    def validate_student_data(data):\n",
    "        \"\"\"Validate student data structure\"\"\"\n",
    "        required_fields = ['id', 'name', 'grade']\n",
    "        \n",
    "        if not isinstance(data, dict):\n",
    "            return False, \"Data must be a dictionary\"\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if field not in data:\n",
    "                return False, f\"Missing required field: {field}\"\n",
    "        \n",
    "        if not isinstance(data['id'], int) or data['id'] <= 0:\n",
    "            return False, \"ID must be a positive integer\"\n",
    "        \n",
    "        if not isinstance(data['name'], str) or not data['name'].strip():\n",
    "            return False, \"Name must be a non-empty string\"\n",
    "        \n",
    "        if not isinstance(data['grade'], (int, float)) or not (0 <= data['grade'] <= 100):\n",
    "            return False, \"Grade must be a number between 0 and 100\"\n",
    "        \n",
    "        return True, \"Valid\"\n",
    "    \n",
    "    # Test validation\n",
    "    test_students = [\n",
    "        {'id': 1, 'name': 'Alice', 'grade': 85},  # Valid\n",
    "        {'id': -1, 'name': 'Bob', 'grade': 90},   # Invalid ID\n",
    "        {'id': 2, 'name': '', 'grade': 75},       # Invalid name\n",
    "        {'id': 3, 'name': 'Charlie', 'grade': 150} # Invalid grade\n",
    "    ]\n",
    "    \n",
    "    for i, student in enumerate(test_students):\n",
    "        is_valid, message = validate_student_data(student)\n",
    "        status = \"✅\" if is_valid else \"❌\"\n",
    "        print(f\"   {status} Student {i+1}: {message}\")\n",
    "    \n",
    "    # 4. Use appropriate pickle protocol\n",
    "    print(\"\\n4. ✅ Use appropriate pickle protocol\")\n",
    "    \n",
    "    test_data = {'version': '1.0', 'data': [1, 2, 3, 4, 5]}\n",
    "    \n",
    "    # Different protocols\n",
    "    protocols = [2, 3, 4, pickle.HIGHEST_PROTOCOL]\n",
    "    \n",
    "    for protocol in protocols:\n",
    "        filename = f'../sample_files/protocol_{protocol}.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(test_data, f, protocol=protocol)\n",
    "        \n",
    "        file_size = os.path.getsize(filename)\n",
    "        print(f\"   Protocol {protocol}: {file_size} bytes\")\n",
    "    \n",
    "    print(f\"   💡 Use protocol {pickle.HIGHEST_PROTOCOL} for best performance\")\n",
    "    \n",
    "    # 5. Security warning\n",
    "    print(\"\\n5. ⚠️ Security Warning\")\n",
    "    print(\"   ❌ NEVER load pickle files from untrusted sources!\")\n",
    "    print(\"   ❌ Pickle can execute arbitrary code during deserialization\")\n",
    "    print(\"   ✅ For untrusted data, use JSON or other safe formats\")\n",
    "    \n",
    "    # Clean up protocol test files\n",
    "    for protocol in protocols:\n",
    "        filename = f'../sample_files/protocol_{protocol}.pkl'\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "\n",
    "demonstrate_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Key Takeaways\n",
    "\n",
    "### Binary File Modes\n",
    "- **`rb`**: Read binary files\n",
    "- **`wb`**: Write binary files (truncates existing)\n",
    "- **`ab`**: Append to binary files\n",
    "- **`rb+`, `wb+`, `ab+`**: Combined read/write modes\n",
    "\n",
    "### Pickle Operations\n",
    "- **`pickle.dump(obj, file)`**: Serialize object to file\n",
    "- **`pickle.load(file)`**: Deserialize object from file\n",
    "- **`pickle.dumps(obj)`**: Serialize to bytes\n",
    "- **`pickle.loads(bytes)`**: Deserialize from bytes\n",
    "\n",
    "### Best Practices\n",
    "1. **Always use context managers** (`with` statement)\n",
    "2. **Handle exceptions** properly\n",
    "3. **Validate data** after loading\n",
    "4. **Use appropriate protocols** for performance\n",
    "5. **Never trust untrusted pickle files** (security risk)\n",
    "\n",
    "### Performance Benefits\n",
    "- **Faster** read/write operations\n",
    "- **Smaller** file sizes\n",
    "- **Preserves** Python data types\n",
    "- **No encoding/decoding** overhead\n",
    "\n",
    "## 🚨 Security Warning\n",
    "\n",
    "**NEVER** load pickle files from untrusted sources! Pickle can execute arbitrary code during deserialization, making it a security risk. For untrusted data, use safer formats like JSON.\n",
    "\n",
    "## 🔜 What's Next?\n",
    "\n",
    "In the next notebook, we'll explore CSV file operations, which provide a safer and more portable way to store structured data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

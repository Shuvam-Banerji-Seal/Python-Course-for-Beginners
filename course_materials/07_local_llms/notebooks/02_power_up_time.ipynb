{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âš¡ Power-Up Time! Understanding AI Models âš¡\n",
    "\n",
    "## Welcome Back, AI Trainer! ğŸ¯\n",
    "\n",
    "Great job completing your first AI adventure! Now it's time to **POWER UP** and learn about different AI models! Think of this like learning about different PokÃ©mon types - each AI model has its own strengths, weaknesses, and special abilities! ğŸ”¥\n",
    "\n",
    "### What You'll Master Today ğŸ†\n",
    "\n",
    "- **ğŸ­ Model Personalities**: Different AI models have different \"personalities\"\n",
    "- **ğŸ“Š Size vs Performance**: Why bigger isn't always better\n",
    "- **âš¡ Speed vs Quality**: The eternal trade-off\n",
    "- **ğŸ¯ Choosing the Right Model**: Match the model to your mission\n",
    "- **ğŸ”§ Model Comparison**: Battle of the AIs!\n",
    "- **ğŸŒŸ Advanced Features**: Special abilities of different models\n",
    "\n",
    "### The AI Model Universe ğŸŒŒ\n",
    "\n",
    "Just like how anime has different genres (shonen, slice-of-life, mecha), AI models come in different \"flavors\":\n",
    "\n",
    "- **ğŸ’¬ Chat Models**: Great at conversations (like having a friend to talk to)\n",
    "- **ğŸ’» Code Models**: Programming wizards (like having a coding sensei)\n",
    "- **ğŸ“š Instruction Models**: Follow directions perfectly (like a loyal sidekick)\n",
    "- **ğŸ¨ Creative Models**: Storytellers and artists (like a creative genius)\n",
    "\n",
    "Let's explore this amazing world! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting Up Our Model Laboratory ğŸ§ª\n",
    "\n",
    "First, let's create our advanced AI model testing laboratory!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our power-up tools! âš¡\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Import our AI companion from the previous notebook\n",
    "class AdvancedAICompanion:\n",
    "    \"\"\"An upgraded AI companion with model comparison abilities! ğŸš€\"\"\"\n",
    "    \n",
    "    def __init__(self, name=\"AI-Master\", ollama_url=\"http://localhost:11434\"):\n",
    "        self.name = name\n",
    "        self.ollama_url = ollama_url\n",
    "        self.model_stats = {}\n",
    "        self.battle_results = []\n",
    "        \n",
    "        print(f\"ğŸŒŸ {self.name} is ready for advanced AI training!\")\n",
    "    \n",
    "    def check_ollama_status(self):\n",
    "        \"\"\"Check if our AI summoning circle is active! ğŸ”®\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.ollama_url}/api/tags\", timeout=5)\n",
    "            return response.status_code == 200\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Get detailed info about all available AI models! ğŸ“Š\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.ollama_url}/api/tags\")\n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get('models', [])\n",
    "                \n",
    "                model_data = []\n",
    "                for model in models:\n",
    "                    name = model.get('name', 'Unknown')\n",
    "                    size_bytes = model.get('size', 0)\n",
    "                    size_gb = size_bytes / (1024**3)\n",
    "                    modified = model.get('modified_at', '')[:10]\n",
    "                    \n",
    "                    # Determine model type based on name\n",
    "                    model_type = self.classify_model_type(name)\n",
    "                    \n",
    "                    model_data.append({\n",
    "                        'Name': name,\n",
    "                        'Type': model_type,\n",
    "                        'Size (GB)': f\"{size_gb:.1f}\",\n",
    "                        'Modified': modified,\n",
    "                        'Power Level': self.estimate_power_level(name, size_gb)\n",
    "                    })\n",
    "                \n",
    "                return pd.DataFrame(model_data)\n",
    "            return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error getting model info: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def classify_model_type(self, model_name):\n",
    "        \"\"\"Classify what type of AI model this is! ğŸ­\"\"\"\n",
    "        name_lower = model_name.lower()\n",
    "        \n",
    "        if 'code' in name_lower:\n",
    "            return 'ğŸ’» Code Wizard'\n",
    "        elif 'chat' in name_lower:\n",
    "            return 'ğŸ’¬ Chat Master'\n",
    "        elif 'instruct' in name_lower:\n",
    "            return 'ğŸ“š Instruction Follower'\n",
    "        elif 'mistral' in name_lower:\n",
    "            return 'ğŸŒªï¸ Speed Demon'\n",
    "        elif 'llama' in name_lower:\n",
    "            return 'ğŸ¦™ All-Rounder'\n",
    "        elif 'phi' in name_lower:\n",
    "            return 'âš¡ Tiny Titan'\n",
    "        else:\n",
    "            return 'ğŸ¤– General AI'\n",
    "    \n",
    "    def estimate_power_level(self, model_name, size_gb):\n",
    "        \"\"\"Estimate the power level like Dragon Ball! ğŸ‰\"\"\"\n",
    "        base_power = int(size_gb * 1000)  # Base power from size\n",
    "        \n",
    "        # Bonus power for special models\n",
    "        name_lower = model_name.lower()\n",
    "        if 'code' in name_lower:\n",
    "            base_power += 2000  # Coding bonus\n",
    "        if 'chat' in name_lower:\n",
    "            base_power += 1500  # Conversation bonus\n",
    "        if 'mistral' in name_lower:\n",
    "            base_power += 1000  # Speed bonus\n",
    "        \n",
    "        return f\"{base_power:,}\"\n",
    "\n",
    "# Create our advanced AI companion\n",
    "ai_master = AdvancedAICompanion()\n",
    "print(\"ğŸ¯ Advanced AI Laboratory is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Discovery Dashboard ğŸ“Š\n",
    "\n",
    "Let's create an awesome dashboard to explore all your AI models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dashboard():\n",
    "    \"\"\"Create an epic model discovery dashboard! ğŸ®\"\"\"\n",
    "    \n",
    "    if not ai_master.check_ollama_status():\n",
    "        return widgets.HTML(\"<p style='color: red;'>âŒ Ollama is not running! Please start it first.</p>\")\n",
    "    \n",
    "    # Get model information\n",
    "    model_df = ai_master.get_model_info()\n",
    "    \n",
    "    if model_df.empty:\n",
    "        return widgets.HTML(\"<p style='color: orange;'>ğŸ“­ No models found! Download some models first.</p>\")\n",
    "    \n",
    "    # Create widgets\n",
    "    refresh_button = widgets.Button(\n",
    "        description='ğŸ”„ Refresh Models',\n",
    "        button_style='info',\n",
    "        icon='sync'\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    def display_models():\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            \n",
    "            print(\"ğŸ­ Your AI Model Collection:\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Display the dataframe\n",
    "            display(model_df)\n",
    "            \n",
    "            # Create visualizations\n",
    "            if len(model_df) > 1:\n",
    "                create_model_visualizations(model_df)\n",
    "    \n",
    "    def refresh_models(b):\n",
    "        nonlocal model_df\n",
    "        model_df = ai_master.get_model_info()\n",
    "        display_models()\n",
    "    \n",
    "    refresh_button.on_click(refresh_models)\n",
    "    \n",
    "    # Initial display\n",
    "    display_models()\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>ğŸ¯ AI Model Discovery Dashboard</h3>\"),\n",
    "        refresh_button,\n",
    "        output_area\n",
    "    ])\n",
    "\n",
    "def create_model_visualizations(model_df):\n",
    "    \"\"\"Create cool visualizations of your models! ğŸ“Š\"\"\"\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('ğŸ® AI Model Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Model Types Distribution\n",
    "    type_counts = model_df['Type'].value_counts()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(type_counts)))\n",
    "    ax1.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "    ax1.set_title('ğŸ­ Model Types Distribution')\n",
    "    \n",
    "    # 2. Model Sizes\n",
    "    sizes = [float(size) for size in model_df['Size (GB)']]\n",
    "    ax2.bar(range(len(sizes)), sizes, color='skyblue', alpha=0.7)\n",
    "    ax2.set_title('ğŸ’¾ Model Sizes (GB)')\n",
    "    ax2.set_xlabel('Models')\n",
    "    ax2.set_ylabel('Size (GB)')\n",
    "    ax2.set_xticks(range(len(model_df)))\n",
    "    ax2.set_xticklabels([name.split(':')[0] for name in model_df['Name']], rotation=45)\n",
    "    \n",
    "    # 3. Power Levels\n",
    "    power_levels = [int(power.replace(',', '')) for power in model_df['Power Level']]\n",
    "    ax3.barh(range(len(power_levels)), power_levels, color='gold', alpha=0.8)\n",
    "    ax3.set_title('âš¡ Power Levels (Dragon Ball Style!)')\n",
    "    ax3.set_xlabel('Power Level')\n",
    "    ax3.set_yticks(range(len(model_df)))\n",
    "    ax3.set_yticklabels([name.split(':')[0] for name in model_df['Name']])\n",
    "    \n",
    "    # 4. Size vs Power Scatter\n",
    "    ax4.scatter(sizes, power_levels, c=colors[:len(sizes)], s=100, alpha=0.7)\n",
    "    ax4.set_title('ğŸ’ª Size vs Power Relationship')\n",
    "    ax4.set_xlabel('Size (GB)')\n",
    "    ax4.set_ylabel('Power Level')\n",
    "    \n",
    "    # Add model names as annotations\n",
    "    for i, name in enumerate(model_df['Name']):\n",
    "        ax4.annotate(name.split(':')[0], (sizes[i], power_levels[i]), \n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ‰ Model analysis complete!\")\n",
    "    print(\"ğŸ’¡ Tip: Larger models are usually more capable but slower!\")\n",
    "\n",
    "# Display the dashboard\n",
    "display(create_model_dashboard())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Great AI Model Battle Arena! âš”ï¸\n",
    "\n",
    "Now let's create an epic battle arena where different AI models compete against each other!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIBattleArena:\n",
    "    \"\"\"Epic AI model battle arena! âš”ï¸ğŸŸï¸\"\"\"\n",
    "    \n",
    "    def __init__(self, ollama_url=\"http://localhost:11434\"):\n",
    "        self.ollama_url = ollama_url\n",
    "        self.battle_history = []\n",
    "    \n",
    "    def get_available_models(self):\n",
    "        \"\"\"Get list of available fighters! ğŸ¥Š\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.ollama_url}/api/tags\")\n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get('models', [])\n",
    "                return [model['name'] for model in models]\n",
    "            return []\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def battle_models(self, model1, model2, challenge_prompt, judge_criteria=\"creativity\"):\n",
    "        \"\"\"Make two AI models battle each other! âš”ï¸\"\"\"\n",
    "        \n",
    "        print(f\"ğŸ¥Š BATTLE ARENA: {model1} vs {model2}\")\n",
    "        print(f\"ğŸ¯ Challenge: {challenge_prompt}\")\n",
    "        print(f\"âš–ï¸ Judged on: {judge_criteria}\")\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        \n",
    "        # Fighter 1\n",
    "        print(f\"ğŸ”¥ {model1} enters the arena!\")\n",
    "        response1, time1 = self.get_model_response(model1, challenge_prompt)\n",
    "        \n",
    "        if response1:\n",
    "            print(f\"ğŸ’¬ {model1}: {response1[:200]}{'...' if len(response1) > 200 else ''}\")\n",
    "            print(f\"â±ï¸ Response time: {time1:.2f} seconds\\n\")\n",
    "        else:\n",
    "            print(f\"âŒ {model1} failed to respond!\\n\")\n",
    "            return None\n",
    "        \n",
    "        # Fighter 2\n",
    "        print(f\"âš¡ {model2} enters the arena!\")\n",
    "        response2, time2 = self.get_model_response(model2, challenge_prompt)\n",
    "        \n",
    "        if response2:\n",
    "            print(f\"ğŸ’¬ {model2}: {response2[:200]}{'...' if len(response2) > 200 else ''}\")\n",
    "            print(f\"â±ï¸ Response time: {time2:.2f} seconds\\n\")\n",
    "        else:\n",
    "            print(f\"âŒ {model2} failed to respond!\\n\")\n",
    "            return None\n",
    "        \n",
    "        # Judge the battle\n",
    "        winner = self.judge_battle(response1, response2, time1, time2, judge_criteria)\n",
    "        \n",
    "        # Record battle results\n",
    "        battle_result = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'model1': model1,\n",
    "            'model2': model2,\n",
    "            'challenge': challenge_prompt,\n",
    "            'criteria': judge_criteria,\n",
    "            'response1': response1,\n",
    "            'response2': response2,\n",
    "            'time1': time1,\n",
    "            'time2': time2,\n",
    "            'winner': winner\n",
    "        }\n",
    "        \n",
    "        self.battle_history.append(battle_result)\n",
    "        \n",
    "        print(f\"ğŸ† WINNER: {winner}!\")\n",
    "        print(\"ğŸ‰ Battle complete!\")\n",
    "        \n",
    "        return battle_result\n",
    "    \n",
    "    def get_model_response(self, model, prompt):\n",
    "        \"\"\"Get response from a model with timing! â±ï¸\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.ollama_url}/api/generate\",\n",
    "                json={\n",
    "                    \"model\": model,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"stream\": False\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                return result.get('response', ''), end_time - start_time\n",
    "            else:\n",
    "                return None, 0\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error with {model}: {e}\")\n",
    "            return None, 0\n",
    "    \n",
    "    def judge_battle(self, response1, response2, time1, time2, criteria):\n",
    "        \"\"\"Judge which AI won the battle! âš–ï¸\"\"\"\n",
    "        \n",
    "        if criteria == \"speed\":\n",
    "            return \"Model 1\" if time1 < time2 else \"Model 2\"\n",
    "        \n",
    "        elif criteria == \"length\":\n",
    "            return \"Model 1\" if len(response1) > len(response2) else \"Model 2\"\n",
    "        \n",
    "        elif criteria == \"creativity\":\n",
    "            # Simple creativity score based on unique words and length\n",
    "            words1 = set(response1.lower().split())\n",
    "            words2 = set(response2.lower().split())\n",
    "            \n",
    "            creativity1 = len(words1) + len(response1) * 0.01\n",
    "            creativity2 = len(words2) + len(response2) * 0.01\n",
    "            \n",
    "            return \"Model 1\" if creativity1 > creativity2 else \"Model 2\"\n",
    "        \n",
    "        else:\n",
    "            # Default: balanced score\n",
    "            score1 = len(response1) * 0.5 + (10 / max(time1, 0.1)) * 0.5\n",
    "            score2 = len(response2) * 0.5 + (10 / max(time2, 0.1)) * 0.5\n",
    "            \n",
    "            return \"Model 1\" if score1 > score2 else \"Model 2\"\n",
    "\n",
    "# Create the battle arena\n",
    "battle_arena = AIBattleArena()\n",
    "print(\"ğŸŸï¸ AI Battle Arena is ready for epic fights!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}